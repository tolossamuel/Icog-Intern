{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsPKX91nIVifa3dGMChnob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tolossamuel/Icog-Intern/blob/main/Prompt_Engineering/Advanced_Prompt_Engineering_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QhvNjZwHgh9Z"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "LT96Ym4mhd0R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0vGQWDeimt8",
        "outputId": "4a3dfdde-ce8c-4cf5-a804-1d0a3aca727c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library\n",
        "import json\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "import time\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "HD6duB9bhteG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gemini api key\n",
        "api_key = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "Nl1z9K_9iFDy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm model\n",
        "genai.configure(api_key=api_key)\n",
        "print(\"Gemini API Key configured successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgka0iStiuDt",
        "outputId": "407d73a6-105d-4853-ddc5-379713ed56d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API Key configured successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the Gemini model\n",
        "# Other options: 'gemini-1.5-flash-latest', 'gemini-1.0-pro', etc.\n",
        "ANALYSIS_MODEL_NAME = 'gemini-1.5-flash-latest'\n",
        "RESPONSE_MODEL_NAME = 'gemini-1.5-flash-latest'"
      ],
      "metadata": {
        "id": "MTJ_Inf0i2CI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the models\n",
        "try:\n",
        "    analysis_model = genai.GenerativeModel(ANALYSIS_MODEL_NAME)\n",
        "    response_model = genai.GenerativeModel(RESPONSE_MODEL_NAME)\n",
        "    print(f\"Initialized Gemini models: {ANALYSIS_MODEL_NAME}, {RESPONSE_MODEL_NAME}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Gemini models: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnd2C7dfjHYX",
        "outputId": "c1fbd799-0596-4c96-9112-465c1239606c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized Gemini models: gemini-1.5-flash-latest, gemini-1.5-flash-latest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Updated LLM Call Function ---\n",
        "def call_gemini_llm(prompt, model, model_name_for_log):\n",
        "    \"\"\"\n",
        "    Calls the specified Gemini LLM model with the given prompt.\n",
        "    Handles basic errors and safety blocking.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Sending Prompt to {model_name_for_log} ---\")\n",
        "    # print(prompt) # Uncomment to see the full prompt being sent\n",
        "    print(\"--- Waiting for Gemini response... ---\")\n",
        "\n",
        "    try:\n",
        "        # Use generate_content for non-streaming\n",
        "        response = model.generate_content(\n",
        "            prompt\n",
        "            )\n",
        "\n",
        "        print(f\"--- Received Response from {model_name_for_log} ---\")\n",
        "\n",
        "        # Check for safety blocks or other issues before accessing text\n",
        "        if not response.candidates:\n",
        "             print(\"Warning: No candidates received from Gemini. Potential block or issue.\")\n",
        "             # Check prompt feedback if available\n",
        "             try:\n",
        "                 print(f\"Prompt Feedback: {response.prompt_feedback}\")\n",
        "             except ValueError:\n",
        "                 print(\"Prompt Feedback not available.\")\n",
        "             return None # Indicate failure\n",
        "\n",
        "        # More detailed safety check (optional)\n",
        "        first_candidate = response.candidates[0]\n",
        "        if first_candidate.finish_reason != 1: # 1 typically means \"STOP\" (successful completion)\n",
        "             print(f\"Warning: Generation finished with reason: {first_candidate.finish_reason}\")\n",
        "             print(f\"Safety Ratings: {first_candidate.safety_ratings}\")\n",
        "             # Consider returning None or handling based on finish_reason/safety_ratings\n",
        "\n",
        "        # Attempt to get text, handle potential errors if part is missing\n",
        "        try:\n",
        "            response_text = response.text\n",
        "            # print(response_text) # Uncomment to see raw response text\n",
        "            print(\"--- Gemini Call Complete ---\")\n",
        "            return response_text\n",
        "        except ValueError as e:\n",
        "             # This can happen if the response was blocked entirely after generation started.\n",
        "             print(f\"Error extracting text from Gemini response: {e}\")\n",
        "             print(f\"Prompt Feedback: {response.prompt_feedback}\")\n",
        "             print(f\"Finish Reason: {first_candidate.finish_reason}\")\n",
        "             print(f\"Safety Ratings: {first_candidate.safety_ratings}\")\n",
        "             return None # Indicate failure\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Gemini API call ({model_name_for_log}): {e}\")\n",
        "        return None # Indicate failure"
      ],
      "metadata": {
        "id": "F1bUQ8k7jKX6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Technique 1: Chain-of-Thought (CoT) for Analysis\n",
        "ANALYSIS_PROMPT_TEMPLATE = \"\"\"\n",
        "Analyze the following customer feedback. Provide your analysis *strictly* in JSON format with the keys \"sentiment\", \"key_issues\", and \"reasoning\".\n",
        "\n",
        "Sentiment should be one of: \"Positive\", \"Negative\", \"Neutral\".\n",
        "Key issues should be a list of specific topics or problems mentioned (even for positive feedback, list the positive aspects).\n",
        "Reasoning should explain your step-by-step thinking process to arrive at the sentiment and key issues (Chain-of-Thought). Ensure the final output is only the valid JSON object.\n",
        "\n",
        "Customer Feedback:\n",
        "\"{feedback_text}\"\n",
        "\n",
        "JSON Analysis:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4icP5G1KjpWE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Technique 2: Few-Shot Prompting for Response Generation\n",
        "RESPONSE_PROMPT_TEMPLATE = \"\"\"\n",
        "You are a helpful and empathetic customer support agent for our company.\n",
        "Draft a customer support response based on the original feedback and its analysis.\n",
        "Keep the tone professional, empathetic, and constructive. Address the key issues identified. Be concise but thorough.\n",
        "\n",
        "Here are some examples of good responses:\n",
        "\n",
        "--- Example 1 ---\n",
        "Feedback: The app is amazing! So easy to use and looks great.\n",
        "Analysis: {{ \"sentiment\": \"Positive\", \"key_issues\": [\"Ease of use\", \"Design\"], \"reasoning\": \"...\" }}\n",
        "Response: Thank you so much for your positive feedback! We're thrilled to hear you find the app easy to use and visually appealing. We appreciate you being a customer!\n",
        "\n",
        "--- Example 2 ---\n",
        "Feedback: Your checkout process is broken! I couldn't complete my purchase because the payment button didn't work. Very frustrating.\n",
        "Analysis: {{ \"sentiment\": \"Negative\", \"key_issues\": [\"Checkout process broken\", \"Payment button not working\"], \"reasoning\": \"...\" }}\n",
        "Response: We sincerely apologize for the frustration you experienced with our checkout process. We understand how important a smooth purchase experience is, and we're sorry the payment button wasn't working for you. Our technical team has been notified and is investigating this issue urgently. We appreciate your patience and for bringing this to our attention.\n",
        "\n",
        "--- Example 3 ---\n",
        "Feedback: The new feature is okay, but I think it could be improved by adding X.\n",
        "Analysis: {{ \"sentiment\": \"Neutral\", \"key_issues\": [\"New feature feedback\", \"Suggestion for improvement X\"], \"reasoning\": \"...\" }}\n",
        "Response: Thank you for sharing your thoughts on the new feature. We appreciate you taking the time to provide feedback and your suggestion about adding X. We'll pass this along to our product team for consideration as we continue to improve the feature based on user input.\n",
        "\n",
        "--- Now, draft a response for the following ---\n",
        "\n",
        "Original Feedback:\n",
        "\"{feedback_text}\"\n",
        "\n",
        "Analysis:\n",
        "{analysis_json}\n",
        "\n",
        "Draft Response:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "2yyB-6VDjxU3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_feedback(feedback):\n",
        "    \"\"\"\n",
        "    Analyzes customer feedback using the Gemini LLM with Chain-of-Thought prompting.\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> Step 1: Analyzing Feedback...\")\n",
        "    prompt = ANALYSIS_PROMPT_TEMPLATE.format(feedback_text=feedback)\n",
        "\n",
        "    raw_response = call_gemini_llm(prompt, analysis_model, f\"{ANALYSIS_MODEL_NAME} (Analysis CoT)\")\n",
        "\n",
        "    if raw_response is None:\n",
        "        print(\"Error: Failed to get analysis response from Gemini.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Gemini might sometimes add ```json ... ``` markers, try to remove them\n",
        "        if raw_response.strip().startswith(\"```json\"):\n",
        "             raw_response = raw_response.strip()[7:-3].strip()\n",
        "        elif raw_response.strip().startswith(\"```\"):\n",
        "             raw_response = raw_response.strip()[3:-3].strip()\n",
        "\n",
        "        analysis_result = json.loads(raw_response)\n",
        "\n",
        "        # Basic validation\n",
        "        if not all(k in analysis_result for k in [\"sentiment\", \"key_issues\", \"reasoning\"]):\n",
        "            print(\"Error: Gemini analysis response is missing required keys.\")\n",
        "            print(f\"Raw Response causing error: {raw_response}\")\n",
        "            return None # Failed validation\n",
        "\n",
        "        print(\">>> Analysis Complete:\")\n",
        "        print(f\"   Sentiment: {analysis_result.get('sentiment')}\")\n",
        "        print(f\"   Key Issues: {analysis_result.get('key_issues')}\")\n",
        "        # print(f\"   Reasoning: {analysis_result.get('reasoning')}\") # Optional\n",
        "        return analysis_result\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Failed to decode JSON response from Gemini analysis.\")\n",
        "        print(f\"Raw Response: {raw_response}\")\n",
        "        return None # Failed JSON parsing\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing analysis response: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Li24-Wvxj3ia"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(feedback, analysis_result):\n",
        "    \"\"\"\n",
        "    Generates a draft response using the Gemini LLM with Few-Shot prompting.\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> Step 2: Generating Response...\")\n",
        "    if not analysis_result:\n",
        "        print(\"Error: Cannot generate response without valid analysis.\")\n",
        "        return None\n",
        "\n",
        "    # Convert analysis dict back to JSON string for the prompt\n",
        "    analysis_json = json.dumps(analysis_result, indent=2)\n",
        "\n",
        "    prompt = RESPONSE_PROMPT_TEMPLATE.format(\n",
        "        feedback_text=feedback,\n",
        "        analysis_json=analysis_json\n",
        "    )\n",
        "\n",
        "    draft_response = call_gemini_llm(prompt, response_model, f\"{RESPONSE_MODEL_NAME} (Response Few-Shot)\")\n",
        "\n",
        "    if draft_response is None:\n",
        "        print(\"Error: Failed to get response draft from Gemini.\")\n",
        "        return None\n",
        "\n",
        "    print(\">>> Response Generation Complete:\")\n",
        "    # Clean up potential leading/trailing whitespace or markers if necessary\n",
        "    draft_response_cleaned = draft_response.strip()\n",
        "    print(f\"   Draft Response: {draft_response_cleaned}\")\n",
        "    return draft_response_cleaned\n"
      ],
      "metadata": {
        "id": "1ZuJivWkkO6g"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_customer_feedback(customer_feedback):\n",
        "    \"\"\"\n",
        "    Orchestrates the analysis and response generation process using Gemini.\n",
        "    \"\"\"\n",
        "    print(f\"\\n===== Processing Feedback: '{customer_feedback}' =====\")\n",
        "\n",
        "    # Handle empty input edge case\n",
        "    if not customer_feedback or not customer_feedback.strip():\n",
        "        print(\"Error: Input feedback is empty.\")\n",
        "        return {\"error\": \"Empty input feedback\", \"feedback\": customer_feedback}\n",
        "\n",
        "    # Step 1: Analyze Feedback (using CoT with Gemini)\n",
        "    analysis = analyze_feedback(customer_feedback)\n",
        "\n",
        "    if not analysis:\n",
        "        print(\"Processing failed during analysis.\")\n",
        "        # Add delay before retrying if implementing retries\n",
        "        # time.sleep(2)\n",
        "        return {\"error\": \"Analysis failed\", \"feedback\": customer_feedback}\n",
        "\n",
        "    # Add a small delay between API calls to potentially avoid rate limits\n",
        "    time.sleep(1)\n",
        "\n",
        "    # Step 2: Generate Response (using Few-Shot with Gemini)\n",
        "    response = generate_response(customer_feedback, analysis)\n",
        "    time.sleep(1)\n",
        "\n",
        "    if not response:\n",
        "        print(\"Processing failed during response generation.\")\n",
        "        # time.sleep(2) # Delay before potential retry\n",
        "        return {\"error\": \"Response generation failed\", \"feedback\": customer_feedback, \"analysis\": analysis}\n",
        "\n",
        "    print(\"\\n===== Processing Complete =====\")\n",
        "    return {\n",
        "        \"original_feedback\": customer_feedback,\n",
        "        \"analysis\": analysis,\n",
        "        \"draft_response\": response\n",
        "    }"
      ],
      "metadata": {
        "id": "g2si2GIZkSd_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Testing & Evaluation (Unchanged - uses the updated functions) ---\n",
        "\n",
        "test_cases = [\n",
        "    \"The mobile app keeps crashing whenever I try to open the settings page. It's unusable!\", # Negative, Bug\n",
        "    \"\", # Edge Case: Empty String,\n",
        "    \"The website is generally fine, but loading times seem a bit slow sometimes, especially on the dashboard.\", # Neutral/Mixed, Performance\n",
        "    \"Customer support was very unhelpful. They didn't understand my problem and closed the ticket.\", # Negative, Support\n",
        "    \"Is there a way to export my data? I looked but couldn't find an option.\", # Neutral, Question/Feature Request\n",
        "    \"Absolutely love the new dark mode feature! Makes using the app at night so much better. Thank you!\", # Positive, Feature\n",
        "    \"asdfhjkl;\", # Edge Case: Gibberish\n",
        "    \"This is okay I guess but the price is too high compared to competitors.\", # Negative, Pricing\n",
        "]"
      ],
      "metadata": {
        "id": "kVI3rxkSkWjR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "print(\"\\n\\n--- Starting Test Cases ---\")\n",
        "for i, feedback in enumerate(test_cases):\n",
        "    print(f\"\\n--- Test Case {i+1} ---\")\n",
        "    result = process_customer_feedback(feedback)\n",
        "    results.append(result)\n",
        "\n",
        "    # Add a delay between processing test cases to respect potential API rate limits\n",
        "    if \"error\" not in result: # Only delay if successful calls were made\n",
        "         time.sleep(2) # Adjust delay as needed based on API limits (free tier often has strict limits)\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KJf7c8wJkaNE",
        "outputId": "782c63c8-d294-44ff-a8b7-4a4e913ccbc3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Starting Test Cases ---\n",
            "\n",
            "--- Test Case 1 ---\n",
            "\n",
            "===== Processing Feedback: 'The mobile app keeps crashing whenever I try to open the settings page. It's unusable!' =====\n",
            "\n",
            ">>> Step 1: Analyzing Feedback...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Analysis Complete:\n",
            "   Sentiment: Negative\n",
            "   Key Issues: ['Mobile app crashing', 'Settings page inaccessibility', 'App unusability']\n",
            "\n",
            ">>> Step 2: Generating Response...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Response Generation Complete:\n",
            "   Draft Response: We are so sorry to hear you're experiencing crashes when trying to access the settings page in our mobile app. We understand how frustrating and disruptive this must be, and we sincerely apologize for the inconvenience.  Our technical team is actively working to identify and resolve this issue.  Could you please provide us with your device's operating system and app version number so we can better investigate?  In the meantime, please know that we are prioritizing a fix to restore full functionality to the app. We appreciate your patience and understanding.\n",
            "\n",
            "===== Processing Complete =====\n",
            "--------------------\n",
            "\n",
            "--- Test Case 2 ---\n",
            "\n",
            "===== Processing Feedback: '' =====\n",
            "Error: Input feedback is empty.\n",
            "--------------------\n",
            "\n",
            "--- Test Case 3 ---\n",
            "\n",
            "===== Processing Feedback: 'The website is generally fine, but loading times seem a bit slow sometimes, especially on the dashboard.' =====\n",
            "\n",
            ">>> Step 1: Analyzing Feedback...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Analysis Complete:\n",
            "   Sentiment: Negative\n",
            "   Key Issues: ['Slow loading times', 'Dashboard performance']\n",
            "\n",
            ">>> Step 2: Generating Response...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Response Generation Complete:\n",
            "   Draft Response: Thank you for your feedback regarding our website's loading times. We appreciate you bringing this to our attention, especially the slow performance you've experienced on the dashboard.  We understand that slow loading speeds can be frustrating, and we're actively working to improve the overall website performance and specifically address the dashboard's speed.  We'll keep you updated on our progress.  In the meantime, please don't hesitate to contact us if you experience further issues.\n",
            "\n",
            "===== Processing Complete =====\n",
            "--------------------\n",
            "\n",
            "--- Test Case 4 ---\n",
            "\n",
            "===== Processing Feedback: 'Customer support was very unhelpful. They didn't understand my problem and closed the ticket.' =====\n",
            "\n",
            ">>> Step 1: Analyzing Feedback...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Analysis Complete:\n",
            "   Sentiment: Negative\n",
            "   Key Issues: ['Unhelpful customer support', 'Lack of understanding from support representative', 'Premature ticket closure']\n",
            "\n",
            ">>> Step 2: Generating Response...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Response Generation Complete:\n",
            "   Draft Response: We sincerely apologize that your recent experience with our customer support team was unhelpful and frustrating. We understand your concern about the lack of understanding regarding your problem and the premature closure of your ticket.  This is certainly not the level of service we aim to provide.\n",
            "\n",
            "Could you please provide more details about your issue so we can better understand what happened and ensure it doesn't happen again?  We'd appreciate it if you could either reply to this email or create a new ticket with as much information as possible about the problem you encountered.  We are committed to resolving your issue and improving our customer support experience.\n",
            "\n",
            "===== Processing Complete =====\n",
            "--------------------\n",
            "\n",
            "--- Test Case 5 ---\n",
            "\n",
            "===== Processing Feedback: 'Is there a way to export my data? I looked but couldn't find an option.' =====\n",
            "\n",
            ">>> Step 1: Analyzing Feedback...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Analysis Complete:\n",
            "   Sentiment: Negative\n",
            "   Key Issues: ['Lack of data export functionality']\n",
            "\n",
            ">>> Step 2: Generating Response...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Response Generation Complete:\n",
            "   Draft Response: We apologize that you were unable to find a data export option.  We understand the importance of being able to access and manage your data.  We're currently reviewing our options for adding data export functionality and appreciate you bringing this to our attention. We will update you on our progress.  Thank you for your understanding.\n",
            "\n",
            "===== Processing Complete =====\n",
            "--------------------\n",
            "\n",
            "--- Test Case 6 ---\n",
            "\n",
            "===== Processing Feedback: 'Absolutely love the new dark mode feature! Makes using the app at night so much better. Thank you!' =====\n",
            "\n",
            ">>> Step 1: Analyzing Feedback...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Analysis Complete:\n",
            "   Sentiment: Positive\n",
            "   Key Issues: ['Positive feedback on dark mode', 'Improved night-time usability']\n",
            "\n",
            ">>> Step 2: Generating Response...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Response Generation Complete:\n",
            "   Draft Response: We're thrilled to hear you're loving the new dark mode feature!  Thank you for your wonderful feedback. We appreciate you taking the time to share your positive experience, and we're delighted that it's improved your nighttime app usage.  We're glad you enjoy it!\n",
            "\n",
            "===== Processing Complete =====\n",
            "--------------------\n",
            "\n",
            "--- Test Case 7 ---\n",
            "\n",
            "===== Processing Feedback: 'asdfhjkl;' =====\n",
            "\n",
            ">>> Step 1: Analyzing Feedback...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Analysis Complete:\n",
            "   Sentiment: Neutral\n",
            "   Key Issues: ['Unintelligible feedback']\n",
            "\n",
            ">>> Step 2: Generating Response...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Response Generation Complete:\n",
            "   Draft Response: We appreciate you contacting us.  Unfortunately, your feedback (\"asdfhjkl;\") wasn't clear enough for us to understand your experience.  Could you please provide more details about what you'd like to share?  Knowing more about your interaction with our product or service will help us assist you better.\n",
            "\n",
            "===== Processing Complete =====\n",
            "--------------------\n",
            "\n",
            "--- Test Case 8 ---\n",
            "\n",
            "===== Processing Feedback: 'This is okay I guess but the price is too high compared to competitors.' =====\n",
            "\n",
            ">>> Step 1: Analyzing Feedback...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Analysis CoT) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Analysis Complete:\n",
            "   Sentiment: Negative\n",
            "   Key Issues: ['High price', 'Competitor pricing']\n",
            "\n",
            ">>> Step 2: Generating Response...\n",
            "\n",
            "--- Sending Prompt to gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Waiting for Gemini response... ---\n",
            "--- Received Response from gemini-1.5-flash-latest (Response Few-Shot) ---\n",
            "--- Gemini Call Complete ---\n",
            ">>> Response Generation Complete:\n",
            "   Draft Response: We appreciate you sharing your feedback. We understand your concern about the price point compared to our competitors.  We strive to offer a competitive product, and we'll review our pricing strategy to ensure it aligns with market value. Thank you for bringing this to our attention.\n",
            "\n",
            "===== Processing Complete =====\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n--- Test Results Summary ---\")\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"\\nTest Case {i+1}:\")\n",
        "    if \"error\" in result:\n",
        "        print(f\"  Status: FAILED ({result['error']})\")\n",
        "        print(f\"  Input: '{result.get('feedback', test_cases[i])}'\")\n",
        "    else:\n",
        "        print(f\"  Status: SUCCESS\")\n",
        "        print(f\"  Input: '{result['original_feedback']}'\")\n",
        "        print(f\"  Sentiment: {result['analysis']['sentiment']}\")\n",
        "        print(f\"  Key Issues: {result['analysis']['key_issues']}\")\n",
        "        # print(f\"  CoT Reasoning: {result['analysis']['reasoning']}\") # Can be verbose\n",
        "        print(f\"  Draft Response: {result['draft_response']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eww5SQndkcth",
        "outputId": "3af6496a-1f42-4053-d4f8-274e81fa2f1c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Test Results Summary ---\n",
            "\n",
            "Test Case 1:\n",
            "  Status: SUCCESS\n",
            "  Input: 'The mobile app keeps crashing whenever I try to open the settings page. It's unusable!'\n",
            "  Sentiment: Negative\n",
            "  Key Issues: ['Mobile app crashing', 'Settings page inaccessibility', 'App unusability']\n",
            "  Draft Response: We are so sorry to hear you're experiencing crashes when trying to access the settings page in our mobile app. We understand how frustrating and disruptive this must be, and we sincerely apologize for the inconvenience.  Our technical team is actively working to identify and resolve this issue.  Could you please provide us with your device's operating system and app version number so we can better investigate?  In the meantime, please know that we are prioritizing a fix to restore full functionality to the app. We appreciate your patience and understanding.\n",
            "\n",
            "Test Case 2:\n",
            "  Status: FAILED (Empty input feedback)\n",
            "  Input: ''\n",
            "\n",
            "Test Case 3:\n",
            "  Status: SUCCESS\n",
            "  Input: 'The website is generally fine, but loading times seem a bit slow sometimes, especially on the dashboard.'\n",
            "  Sentiment: Negative\n",
            "  Key Issues: ['Slow loading times', 'Dashboard performance']\n",
            "  Draft Response: Thank you for your feedback regarding our website's loading times. We appreciate you bringing this to our attention, especially the slow performance you've experienced on the dashboard.  We understand that slow loading speeds can be frustrating, and we're actively working to improve the overall website performance and specifically address the dashboard's speed.  We'll keep you updated on our progress.  In the meantime, please don't hesitate to contact us if you experience further issues.\n",
            "\n",
            "Test Case 4:\n",
            "  Status: SUCCESS\n",
            "  Input: 'Customer support was very unhelpful. They didn't understand my problem and closed the ticket.'\n",
            "  Sentiment: Negative\n",
            "  Key Issues: ['Unhelpful customer support', 'Lack of understanding from support representative', 'Premature ticket closure']\n",
            "  Draft Response: We sincerely apologize that your recent experience with our customer support team was unhelpful and frustrating. We understand your concern about the lack of understanding regarding your problem and the premature closure of your ticket.  This is certainly not the level of service we aim to provide.\n",
            "\n",
            "Could you please provide more details about your issue so we can better understand what happened and ensure it doesn't happen again?  We'd appreciate it if you could either reply to this email or create a new ticket with as much information as possible about the problem you encountered.  We are committed to resolving your issue and improving our customer support experience.\n",
            "\n",
            "Test Case 5:\n",
            "  Status: SUCCESS\n",
            "  Input: 'Is there a way to export my data? I looked but couldn't find an option.'\n",
            "  Sentiment: Negative\n",
            "  Key Issues: ['Lack of data export functionality']\n",
            "  Draft Response: We apologize that you were unable to find a data export option.  We understand the importance of being able to access and manage your data.  We're currently reviewing our options for adding data export functionality and appreciate you bringing this to our attention. We will update you on our progress.  Thank you for your understanding.\n",
            "\n",
            "Test Case 6:\n",
            "  Status: SUCCESS\n",
            "  Input: 'Absolutely love the new dark mode feature! Makes using the app at night so much better. Thank you!'\n",
            "  Sentiment: Positive\n",
            "  Key Issues: ['Positive feedback on dark mode', 'Improved night-time usability']\n",
            "  Draft Response: We're thrilled to hear you're loving the new dark mode feature!  Thank you for your wonderful feedback. We appreciate you taking the time to share your positive experience, and we're delighted that it's improved your nighttime app usage.  We're glad you enjoy it!\n",
            "\n",
            "Test Case 7:\n",
            "  Status: SUCCESS\n",
            "  Input: 'asdfhjkl;'\n",
            "  Sentiment: Neutral\n",
            "  Key Issues: ['Unintelligible feedback']\n",
            "  Draft Response: We appreciate you contacting us.  Unfortunately, your feedback (\"asdfhjkl;\") wasn't clear enough for us to understand your experience.  Could you please provide more details about what you'd like to share?  Knowing more about your interaction with our product or service will help us assist you better.\n",
            "\n",
            "Test Case 8:\n",
            "  Status: SUCCESS\n",
            "  Input: 'This is okay I guess but the price is too high compared to competitors.'\n",
            "  Sentiment: Negative\n",
            "  Key Issues: ['High price', 'Competitor pricing']\n",
            "  Draft Response: We appreciate you sharing your feedback. We understand your concern about the price point compared to our competitors.  We strive to offer a competitive product, and we'll review our pricing strategy to ensure it aligns with market value. Thank you for bringing this to our attention.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mcqQvIUQk3Rv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}